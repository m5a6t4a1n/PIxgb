import streamlit as st
import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
from io import BytesIO
import traceback
import json

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="PIé¢„æµ‹æ¨¡å‹",
    page_icon="ğŸ¥",
    layout="wide"
)

# ä½œè€…å’Œå•ä½ä¿¡æ¯
AUTHOR_INFO = {
    "author": "çŸ³å±‚å±‚",
    "institution": "å±±ä¸œè¯å“é£Ÿå“èŒä¸šå­¦é™¢"
}

# åŠ è½½å¹¶ä¿®å¤XGBoostæ¨¡å‹
@st.cache_resource
def load_and_fix_model():
    try:
        import joblib
        import xgboost as xgb
        
        # å°è¯•åŠ è½½æ¨¡å‹
        model = joblib.load('xgb.pkl')
        
        # æ£€æŸ¥æ¨¡å‹ç±»å‹
        # st.write(f"æ¨¡å‹ç±»å‹: {type(model)}")
        
        # å¦‚æœæ˜¯XGBoostæ¨¡å‹ï¼Œå°è¯•ä¿®å¤base_score
        if hasattr(model, 'save_config'):
            try:
                # è·å–æ¨¡å‹é…ç½®
                config = model.save_config()
                config_dict = json.loads(config)
                
                # ä¿®å¤base_score
                if 'learner' in config_dict and 'learner_model_param' in config_dict['learner']:
                    learner_model_param = config_dict['learner']['learner_model_param']
                    if 'base_score' in learner_model_param:
                        base_score_str = learner_model_param['base_score']
                        st.write(f"åŸå§‹base_score: {base_score_str}")
                        
                        # ä¿®å¤base_scoreæ ¼å¼
                        if isinstance(base_score_str, str) and base_score_str.startswith('[') and base_score_str.endswith(']'):
                            # æå–æ•°å­—éƒ¨åˆ†
                            base_score_clean = base_score_str.strip('[]')
                            base_score_float = float(base_score_clean)
                            config_dict['learner']['learner_model_param']['base_score'] = str(base_score_float)
                            st.write(f"ä¿®å¤åbase_score: {base_score_float}")
                            
                            # é‡æ–°åŠ è½½é…ç½®
                            model.load_config(json.dumps(config_dict))
                            st.success("æ¨¡å‹base_scoreå‚æ•°å·²ä¿®å¤")
            except Exception as e:
                st.warning(f"ä¿®å¤æ¨¡å‹å‚æ•°æ—¶å‡ºé”™ï¼Œä½†å°†ç»§ç»­ä½¿ç”¨åŸå§‹æ¨¡å‹: {str(e)}")
        
        return model
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        return None

model = load_and_fix_model()

# ç‰¹å¾ç¼©å†™æ˜ å°„
feature_abbreviations = {
    "FCTI": "FCTI",
    "Age": "Age",
    "Ser": "Ser",
    "Fra": "Fra",
    "Air": "Air",
    "Com": "Com",
    "PCAT": "PCAT",
    "Mlu": "Mlu"
}

# ç‰¹å¾èŒƒå›´å®šä¹‰ - ä¼˜åŒ–æ­¥é•¿è®¾ç½®
feature_ranges = {
    "FCTI": {
        "type": "numerical", 
        "min": 0, 
        "max": 40, 
        "default": 12, 
        "step": 1,  # æ•´æ•°æ­¥é•¿
        "label": "FCTIæ€»åˆ†"
    },
    "Age": {
        "type": "numerical", 
        "min": 70, 
        "max": 98, 
        "default": 79, 
        "step": 1,  # æ•´æ•°æ­¥é•¿
        "label": "å¹´é¾„ï¼ˆå²ï¼‰"
    },
    "Ser": {
        "type": "numerical", 
        "min": 20.0, 
        "max": 60.0, 
        "default": 34.2, 
        "step": 0.1,  # å°æ•°æ­¥é•¿
        "label": "è¡€æ¸…ç™½è›‹ç™½ (g/L)"
    },
    "Fra": {
        "type": "categorical", 
        "options": [0,1,2,3,4,5,6,7,8,9,10,11,12,13], 
        "default": 5, 
        "label": "éª¨æŠ˜ç±»å‹", 
        "option_labels": {
            0: "é¢ˆæ¤éª¨æŠ˜", 1: "èƒ¸æ¤éª¨æŠ˜", 2: "è…°æ¤éª¨æŠ˜", 
            3: "è‚¡éª¨é¢ˆéª¨æŠ˜", 4: "è‚¡éª¨ç²—éš†é—´éª¨æŠ˜", 5: "è‚¡éª¨å¹²éª¨æŠ˜", 6: "èƒ«è…“éª¨ä¸Šæ®µéª¨æŠ˜",
            7: "å°¾éª¨ç²‰ç¢æ€§éª¨æŠ˜", 8: "éª¶é«‚å…³èŠ‚è„±ä½", 9: "é«‹éª¨éª¨æŠ˜", 
            10: "é«Œéª¨ç²‰ç¢æ€§éª¨æŠ˜", 11: "é«‹å…³èŠ‚å†…éª¨æŠ˜", 12: "è„†æ€§éª¨æŠ˜", 13: "å…¶ä»–"
        }
    },
    "Air": {
        "type": "categorical", 
        "options": [0, 1], 
        "default": 0, 
        "label": "æ°”å«åºŠ/å……æ°”åºŠå«", 
        "option_labels": {0: "æœªä½¿ç”¨", 1: "ä½¿ç”¨"}
    },
    "Com": {
        "type": "numerical", 
        "min": 0, 
        "max": 8, 
        "default": 5, 
        "step": 1,  # æ•´æ•°æ­¥é•¿
        "label": "åˆå¹¶ç—‡æ•°é‡"
    },
    "PCAT": {
        "type": "numerical", 
        "min": 1, 
        "max": 4, 
        "default": 2, 
        "step": 1,  # æ•´æ•°æ­¥é•¿
        "label": "PCATæ€»åˆ†"
    },
    "Mlu": {
        "type": "categorical", 
        "options": [0, 1], 
        "default": 1, 
        "label": "å¤šå‘æ€§éª¨æŠ˜", 
        "option_labels": {0: "å¦", 1: "æ˜¯"}
    },
}

# Streamlit ç•Œé¢
st.title('"åŒ»é™¢-å®¶åº­-ç¤¾åŒº"ä¸‰åŒºè”åˆå»¶ç»­æŠ¤ç†æ¨¡å¼ä¸‹çš„è€å¹´éª¨æŠ˜å§åºŠæ‚£è€…PIé£é™©é¢„æµ‹æ¨¡å‹')

# æ·»åŠ ä½œè€…ä¿¡æ¯
st.markdown(f"""
<div style='text-align: center; color: #666; margin-top: -10px; margin-bottom: 20px;'>
    å¼€å‘å•ä½ï¼š{AUTHOR_INFO["institution"]} | ä½œè€…ï¼š{AUTHOR_INFO["author"]}
</div>
""", unsafe_allow_html=True)

# æ·»åŠ è¯´æ˜æ–‡æœ¬
st.markdown("""
æœ¬åº”ç”¨åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹åœ¨"åŒ»é™¢-å®¶åº­-ç¤¾åŒº"ä¸‰åŒºè”åˆå»¶ç»­æŠ¤ç†æ¨¡å¼ä¸‹çš„è€å¹´éª¨æŠ˜å§åºŠæ‚£è€…PIé£é™©ã€‚
è¯·åœ¨ä¸‹æ–¹çš„è¡¨å•ä¸­è¾“å…¥æ‚£è€…çš„ä¸´åºŠæŒ‡æ ‡ï¼Œç„¶åç‚¹å‡»"å¼€å§‹é¢„æµ‹"æŒ‰é’®ã€‚
""")

# åŠ¨æ€ç”Ÿæˆè¾“å…¥é¡¹
st.header("è¯·è¾“å…¥æ‚£è€…ä¸´åºŠæŒ‡æ ‡:")
feature_values = []

# åˆ›å»ºä¸¤åˆ—å¸ƒå±€
col1, col2 = st.columns(2)

features_list = list(feature_ranges.keys())
half_point = len(features_list) // 2

for i, feature in enumerate(features_list):
    properties = feature_ranges[feature]
    
    if i < half_point:
        with col1:
            if properties["type"] == "numerical":
                # è®¾ç½®æ­¥é•¿
                step = properties.get("step", 1)
                
                # æ ¹æ®æ­¥é•¿ç¡®å®švalueçš„ç±»å‹å’Œæ˜¾ç¤ºæ ¼å¼
                if step == 1:
                    # æ•´æ•°ç‰¹å¾ - ä½¿ç”¨%gæ ¼å¼è‡ªåŠ¨é€‰æ‹©æ•´æ•°æ˜¾ç¤º
                    value = st.number_input(
                        label=f"{properties['label']}",
                        min_value=float(properties["min"]),
                        max_value=float(properties["max"]),
                        value=float(properties["default"]),
                        step=float(step),
                        format="%g",  # ä½¿ç”¨%gæ ¼å¼ï¼Œè‡ªåŠ¨æ˜¾ç¤ºæ•´æ•°
                        help=f"èŒƒå›´: {properties['min']} - {properties['max']}ï¼Œæ¯æ¬¡å¢å‡: {step}"
                    )
                    value = int(value)  # è½¬æ¢ä¸ºæ•´æ•°
                else:
                    # å°æ•°ç‰¹å¾ - æ˜¾ç¤ºä¸€ä½å°æ•°
                    value = st.number_input(
                        label=f"{properties['label']}",
                        min_value=float(properties["min"]),
                        max_value=float(properties["max"]),
                        value=float(properties["default"]),
                        step=float(step),
                        format="%.1f",  # æ˜¾ç¤ºä¸€ä½å°æ•°
                        help=f"èŒƒå›´: {properties['min']} - {properties['max']}ï¼Œæ¯æ¬¡å¢å‡: {step}"
                    )
                    value = round(float(value), 1)  # ä¿ç•™1ä½å°æ•°ï¼Œç¡®ä¿æ˜¯æµ®ç‚¹æ•°
                    
            elif properties["type"] == "categorical":
                option_labels = properties.get("option_labels", {k: str(k) for k in properties["options"]})
                selected_label = st.selectbox(
                    label=f"{properties['label']}",
                    options=properties["options"],
                    format_func=lambda x: option_labels[x],
                    index=properties["options"].index(properties["default"])
                )
                value = int(selected_label)  # ç¡®ä¿æ˜¯æ•´æ•°
            feature_values.append(value)
    else:
        with col2:
            if properties["type"] == "numerical":
                # è®¾ç½®æ­¥é•¿
                step = properties.get("step", 1)
                
                # æ ¹æ®æ­¥é•¿ç¡®å®švalueçš„ç±»å‹å’Œæ˜¾ç¤ºæ ¼å¼
                if step == 1:
                    # æ•´æ•°ç‰¹å¾ - ä½¿ç”¨%gæ ¼å¼è‡ªåŠ¨é€‰æ‹©æ•´æ•°æ˜¾ç¤º
                    value = st.number_input(
                        label=f"{properties['label']}",
                        min_value=float(properties["min"]),
                        max_value=float(properties["max"]),
                        value=float(properties["default"]),
                        step=float(step),
                        format="%g",  # ä½¿ç”¨%gæ ¼å¼ï¼Œè‡ªåŠ¨æ˜¾ç¤ºæ•´æ•°
                        help=f"èŒƒå›´: {properties['min']} - {properties['max']}ï¼Œæ¯æ¬¡å¢å‡: {step}"
                    )
                    value = int(value)  # è½¬æ¢ä¸ºæ•´æ•°
                else:
                    # å°æ•°ç‰¹å¾ - æ˜¾ç¤ºä¸€ä½å°æ•°
                    value = st.number_input(
                        label=f"{properties['label']}",
                        min_value=float(properties["min"]),
                        max_value=float(properties["max"]),
                        value=float(properties["default"]),
                        step=float(step),
                        format="%.1f",  # æ˜¾ç¤ºä¸€ä½å°æ•°
                        help=f"èŒƒå›´: {properties['min']} - {properties['max']}ï¼Œæ¯æ¬¡å¢å‡: {step}"
                    )
                    value = round(float(value), 1)  # ä¿ç•™1ä½å°æ•°ï¼Œç¡®ä¿æ˜¯æµ®ç‚¹æ•°
                    
            elif properties["type"] == "categorical":
                option_labels = properties.get("option_labels", {k: str(k) for k in properties["options"]})
                selected_label = st.selectbox(
                    label=f"{properties['label']}",
                    options=properties["options"],
                    format_func=lambda x: option_labels[x],
                    index=properties["options"].index(properties["default"])
                )
                value = int(selected_label)  # ç¡®ä¿æ˜¯æ•´æ•°
            feature_values.append(value)

# æ˜¾ç¤ºå½“å‰è¾“å…¥å€¼é¢„è§ˆ
with st.expander("ğŸ“‹ å½“å‰è¾“å…¥å€¼é¢„è§ˆ"):
    preview_data = []
    for i, (feature, value) in enumerate(zip(features_list, feature_values)):
        prop = feature_ranges[feature]
        if prop["type"] == "categorical" and "option_labels" in prop:
            display_value = prop["option_labels"].get(int(value), value)
        else:
            # æ ¹æ®ç‰¹å¾ç±»å‹è°ƒæ•´æ˜¾ç¤ºæ ¼å¼
            if feature in ["FCTI", "Age", "Com", "PCAT"]:
                display_value = int(value)  # æ•´æ•°ç‰¹å¾æ˜¾ç¤ºæ•´æ•°
            elif feature == "Ser":
                display_value = round(value, 1)  # Seræ˜¾ç¤ºä¸€ä½å°æ•°
            else:
                display_value = value
        preview_data.append({"ç‰¹å¾": feature_abbreviations[feature], "å€¼": display_value})
    
    preview_df = pd.DataFrame(preview_data)
    st.dataframe(preview_df, use_container_width=True)

st.markdown("---")

# é¢„æµ‹ä¸ SHAP å¯è§†åŒ–
if model is not None and st.button("å¼€å§‹é¢„æµ‹", type="primary"):
    with st.spinner('æ¨¡å‹æ­£åœ¨è®¡ç®—ä¸­ï¼Œè¯·ç¨å€™...'):
        # åˆ›å»ºDataFrameç”¨äºæ¨¡å‹é¢„æµ‹
        features_df = pd.DataFrame([feature_values], columns=features_list)
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
        for col in features_list:
            features_df[col] = pd.to_numeric(features_df[col], errors='coerce')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNå€¼
        if features_df.isnull().any().any():
            st.error("è¾“å…¥å€¼åŒ…å«æ— æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥è¾“å…¥")
            st.stop()

        # æ¨¡å‹é¢„æµ‹
        try:
            # ç¡®ä¿ç‰¹å¾é¡ºåºä¸æ¨¡å‹è®­ç»ƒæ—¶ä¸€è‡´
            if hasattr(model, 'feature_names_in_'):
                # å¦‚æœæ¨¡å‹æœ‰feature_names_in_å±æ€§ï¼Œç¡®ä¿é¡ºåºä¸€è‡´
                expected_features = model.feature_names_in_
                features_df = features_df[expected_features]
            
            predicted_class = model.predict(features_df)[0]
            predicted_proba = model.predict_proba(features_df)[0]
            
            # æå–æ¦‚ç‡
            probability_positive = predicted_proba[1] * 100  # PIå‘ç”Ÿçš„æ¦‚ç‡
            probability_negative = predicted_proba[0] * 100  # ä¸å‘ç”ŸPIçš„æ¦‚ç‡
            
            # æ˜¾ç¤ºçš„PIå‘ç”Ÿæ¦‚ç‡
            probability = probability_positive
            
        except Exception as e:
            st.error(f"æ¨¡å‹é¢„æµ‹æ—¶å‡ºé”™: {str(e)}")
            st.info("è¯·æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®")
            st.stop()

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    st.subheader("é¢„æµ‹ç»“æœ")
    
    # ä½¿ç”¨è¿›åº¦æ¡å’ŒæŒ‡æ ‡æ˜¾ç¤ºPIå‘ç”Ÿæ¦‚ç‡
    st.metric(label="PIå‘ç”Ÿæ¦‚ç‡", value=f"{probability:.2f}%")
    st.progress(min(100, int(probability)))  # ç¡®ä¿ä¸è¶…è¿‡100
    
    # æ·»åŠ é£é™©ç­‰çº§è§£è¯» - åŸºäºPIå‘ç”Ÿæ¦‚ç‡
    if probability < 20:
        risk_level = "ä½é£é™©"
        color = "green"
        recommendation = "å»ºè®®ï¼šå¸¸è§„æŠ¤ç†å³å¯"
    elif probability < 50:
        risk_level = "ä¸­é£é™©"
        color = "orange"
        recommendation = "å»ºè®®ï¼šåŠ å¼ºè§‚å¯Ÿï¼Œå¢åŠ ç¿»èº«é¢‘ç‡"
    else:
        risk_level = "é«˜é£é™©"
        color = "red"
        recommendation = "å»ºè®®ï¼šé‡‡å–å¼ºåŒ–æŠ¤ç†æªæ–½ï¼Œä½¿ç”¨ä¸“ä¸šé˜²å‹ç–®è®¾å¤‡"
    
    st.markdown(f"<h4 style='color: {color};'>é£é™©ç­‰çº§: {risk_level}</h4>", unsafe_allow_html=True)
    st.info(recommendation)
    
    # é¢„æµ‹ç±»åˆ«è§£é‡Š - ä¿®å¤é€»è¾‘
    if probability_positive >= 50:  # ä½¿ç”¨50%ä½œä¸ºé˜ˆå€¼
        st.warning(f"é¢„æµ‹ç»“æœï¼šè¯¥æ‚£è€…å‘ç”ŸPIçš„é£é™©è¾ƒé«˜ (æ¦‚ç‡: {probability_positive:.2f}%)")
    else:
        st.info(f"é¢„æµ‹ç»“æœï¼šè¯¥æ‚£è€…å‘ç”ŸPIçš„é£é™©è¾ƒä½ (æ¦‚ç‡: {probability_positive:.2f}%)")
    
    # åˆ›å»ºç”¨äºSHAPçš„DataFrame
    shap_df = pd.DataFrame([feature_values], columns=features_list)
    shap_df.columns = [feature_abbreviations[col] for col in shap_df.columns]
    
    # è®¡ç®— SHAP å€¼ï¼ˆæ— æç¤ºç‰ˆæœ¬ï¼‰
    with st.spinner('æ­£åœ¨ç”Ÿæˆæ¨¡å‹è§£é‡Šå›¾...'):
        try:
            # åˆ›å»ºä¸€ä¸ªå¹²å‡€çš„æ•°æ®é›†ç”¨äºSHAPè®¡ç®—
            def prepare_shap_data(model, features_df):
                """å‡†å¤‡SHAPè®¡ç®—æ‰€éœ€çš„æ•°æ®ï¼Œä¸æ˜¾ç¤ºä»»ä½•æç¤º"""
                # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
                clean_df = features_df.copy()
                
                # åˆ›å»ºé¢„æµ‹å‡½æ•°
                def model_predict(data):
                    return model.predict_proba(data)[:, 1]
                
                # åˆ›å»ºèƒŒæ™¯æ•°æ®ï¼ˆä½¿ç”¨ç‰¹å¾èŒƒå›´çš„ä¸­é—´å€¼ï¼‰
                background_data = []
                for feature in features_list:
                    prop = feature_ranges[feature]
                    if prop["type"] == "numerical":
                        # ä½¿ç”¨ä¸­é—´å€¼
                        value = (prop["min"] + prop["max"]) / 2
                        if prop.get("step", 1) == 1:
                            value = int(value)
                        else:
                            value = round(value, 1)
                    else:
                        value = prop["default"]
                    background_data.append(value)
                
                background_df = pd.DataFrame([background_data], columns=features_list)
                
                # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
                for col in clean_df.columns:
                    clean_df[col] = pd.to_numeric(clean_df[col], errors='coerce')
                for col in background_df.columns:
                    background_df[col] = pd.to_numeric(background_df[col], errors='coerce')
                
                return clean_df, background_df, model_predict
            
            # å‡†å¤‡æ•°æ®
            clean_df, background_df, model_predict = prepare_shap_data(model, features_df)
            
            # é™é»˜è®¡ç®—SHAPå€¼
            try:
                # é¦–å…ˆå°è¯•ä½¿ç”¨KernelExplainerï¼ˆé¿å…TreeExplainerçš„æç¤ºï¼‰
                explainer = shap.KernelExplainer(model_predict, background_df)
                shap_values = explainer.shap_values(clean_df)
            except Exception:
                # å¦‚æœKernelExplainerå¤±è´¥ï¼Œä½¿ç”¨æ¨¡å‹ç›´æ¥è®¡ç®—
                shap_values = np.zeros((1, len(features_list)))
                for i, col in enumerate(features_list):
                    # ç®€å•è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å½±å“
                    original_pred = model_predict(clean_df)[0]
                    temp_df = clean_df.copy()
                    temp_df[col] = background_df[col].iloc[0]
                    new_pred = model_predict(temp_df)[0]
                    shap_values[0, i] = original_pred - new_pred
            
            # è·å–åŸºå‡†å€¼
            if hasattr(explainer, 'expected_value'):
                if isinstance(explainer.expected_value, (list, np.ndarray)) and len(explainer.expected_value) > 1:
                    base_value = explainer.expected_value[1]
                else:
                    base_value = explainer.expected_value[0] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value
            else:
                base_value = 0.0
            
            # ç¡®ä¿shap_valuesæ˜¯æ­£ç¡®æ ¼å¼
            if isinstance(shap_values, list):
                shap_values = np.array(shap_values).reshape(1, -1)
            elif len(shap_values.shape) == 1:
                shap_values = shap_values.reshape(1, -1)
            
            # ç”Ÿæˆ SHAP åŠ›å›¾
            try:
                plt.figure(figsize=(12, 4), dpi=100)
                shap.force_plot(
                    base_value,
                    shap_values[0],
                    clean_df.iloc[0].values,
                    feature_names=shap_df.columns.tolist(),
                    matplotlib=True,
                    show=False
                )
                
                plt.tight_layout()
                
                buf_force = BytesIO()
                plt.savefig(buf_force, format="png", bbox_inches="tight", dpi=100)
                plt.close()
                force_plot_success = True
            except Exception as e:
                st.warning(f"ç”ŸæˆSHAPåŠ›å›¾æ—¶é‡åˆ°é—®é¢˜ï¼Œå°†æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§å›¾ä»£æ›¿")
                force_plot_success = False
                buf_force = None
            
            # ç”Ÿæˆ SHAP ç€‘å¸ƒå›¾
            try:
                plt.figure(figsize=(12, 6), dpi=100)
                max_display = min(8, len(shap_df.columns))
                
                # åˆ›å»ºExplanationå¯¹è±¡
                exp = shap.Explanation(
                    values=shap_values[0],
                    base_values=base_value,
                    data=clean_df.iloc[0].values,
                    feature_names=shap_df.columns.tolist()
                )
                
                # ç»˜åˆ¶ç€‘å¸ƒå›¾
                shap.plots.waterfall(exp, max_display=max_display, show=False)
                
                plt.tight_layout()
                buf_waterfall = BytesIO()
                plt.savefig(buf_waterfall, format="png", bbox_inches="tight", dpi=100)
                plt.close()
                waterfall_plot_success = True
            except Exception as e:
                waterfall_plot_success = False
                buf_waterfall = None
            
            # æ˜¾ç¤ºSHAPè§£é‡Šå›¾
            st.subheader("æ¨¡å‹è§£é‡Š")
            st.markdown("ä»¥ä¸‹å›¾è¡¨æ˜¾ç¤ºäº†å„ä¸ªç‰¹å¾å˜é‡å¯¹é¢„æµ‹ç»“æœçš„è´¡çŒ®ç¨‹åº¦ï¼š")
            
            # æ˜¾ç¤ºå¯ç”¨çš„å›¾è¡¨
            if force_plot_success and buf_force is not None:
                st.markdown("#### SHAP Force Plot")
                st.image(buf_force, use_column_width=True)
                st.caption("åŠ›å›¾æ˜¾ç¤ºäº†æ¯ä¸ªç‰¹å¾å¦‚ä½•å°†é¢„æµ‹å€¼ä»åŸºå‡†å€¼æ¨å‘æœ€ç»ˆé¢„æµ‹å€¼")
                st.markdown("<br>", unsafe_allow_html=True)
            
            if waterfall_plot_success and buf_waterfall is not None:
                st.markdown("#### SHAP Waterfall Plot")
                st.image(buf_waterfall, use_column_width=True)
                st.caption("ç€‘å¸ƒå›¾æ˜¾ç¤ºäº†æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„ç´¯ç§¯è´¡çŒ®")
            else:
                # å¦‚æœç€‘å¸ƒå›¾å¤±è´¥ï¼Œæ˜¾ç¤ºç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
                st.markdown("#### ç‰¹å¾é‡è¦æ€§")
                
                # è®¡ç®—ç‰¹å¾é‡è¦æ€§
                feature_importance = np.abs(shap_values[0])
                sorted_idx = np.argsort(feature_importance)[-8:]  # å–å‰8ä¸ª
                
                # åˆ›å»ºæ¡å½¢å›¾
                fig, ax = plt.subplots(figsize=(10, 6))
                colors = ['red' if shap_values[0][i] > 0 else 'blue' for i in sorted_idx]
                ax.barh(range(len(sorted_idx)), feature_importance[sorted_idx], color=colors)
                ax.set_yticks(range(len(sorted_idx)))
                ax.set_yticklabels([shap_df.columns[i] for i in sorted_idx])
                ax.set_xlabel("ç‰¹å¾é‡è¦æ€§ (ç»å¯¹SHAPå€¼)")
                ax.set_title("Top 8 ç‰¹å¾é‡è¦æ€§", fontsize=12, pad=20)
                
                # æ·»åŠ å›¾ä¾‹
                from matplotlib.patches import Patch
                legend_elements = [Patch(facecolor='red', label='å¢åŠ PIé£é™©'),
                                  Patch(facecolor='blue', label='é™ä½PIé£é™©')]
                ax.legend(handles=legend_elements, loc='lower right')
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
            
            # æ·»åŠ ç‰¹å¾å½±å“åˆ†æ
            st.subheader("ç‰¹å¾å½±å“åˆ†æ")
            
            # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„SHAPå€¼è´¡çŒ®
            feature_shap = {}
            for i, feature in enumerate(shap_df.columns):
                feature_shap[feature] = shap_values[0][i]
            
            # æŒ‰ç»å¯¹è´¡çŒ®å€¼æ’åº
            sorted_features = sorted(feature_shap.items(), key=lambda x: abs(x[1]), reverse=True)
            
            # æ˜¾ç¤ºå‰5ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            st.markdown("**å¯¹é¢„æµ‹å½±å“æœ€å¤§çš„ç‰¹å¾ï¼š**")
            for feature, shap_value in sorted_features[:5]:
                direction = "å¢åŠ " if shap_value > 0 else "é™ä½"
                color = "red" if shap_value > 0 else "green"
                st.markdown(f"- **{feature}**: <span style='color:{color}'>{direction}PIé£é™©</span> (å½±å“å€¼: {shap_value:.4f})", 
                           unsafe_allow_html=True)
            
            # æ˜¾ç¤ºç‰¹å¾å€¼
            st.subheader("å½“å‰è¾“å…¥çš„ç‰¹å¾å€¼")
            feature_data = []
            for i, (feature, value) in enumerate(zip(shap_df.columns, feature_values)):
                prop = feature_ranges[features_list[i]]
                if prop["type"] == "categorical" and "option_labels" in prop:
                    display_value = prop["option_labels"].get(int(value), value)
                else:
                    # æ ¹æ®ç‰¹å¾ç±»å‹è°ƒæ•´æ˜¾ç¤ºæ ¼å¼
                    if feature_abbreviations[features_list[i]] in ["FCTI", "Age", "Com", "PCAT"]:
                        display_value = int(value)  # æ•´æ•°ç‰¹å¾æ˜¾ç¤ºæ•´æ•°
                    elif feature_abbreviations[features_list[i]] == "Ser":
                        display_value = round(value, 1)  # Seræ˜¾ç¤ºä¸€ä½å°æ•°
                    else:
                        display_value = value
                feature_data.append({"ç‰¹å¾": feature_abbreviations[features_list[i]], "å€¼": display_value})
            
            feature_df = pd.DataFrame(feature_data)
            st.dataframe(feature_df, use_container_width=True)
            
            # æ˜¾ç¤ºæ¦‚ç‡è¯¦æƒ…
            with st.expander("æŸ¥çœ‹è¯¦ç»†æ¦‚ç‡"):
                st.markdown(f"""
                ### é¢„æµ‹æ¦‚ç‡è¯¦æƒ…
                - **å‘ç”ŸPIçš„æ¦‚ç‡**: {probability_positive:.2f}%
                - **ä¸å‘ç”ŸPIçš„æ¦‚ç‡**: {probability_negative:.2f}%
                - **æ¨¡å‹é¢„æµ‹ç±»åˆ«**: {'å‘ç”ŸPI' if predicted_class == 1 else 'ä¸å‘ç”ŸPI'}
                - **å†³ç­–é˜ˆå€¼**: 50%
                - **é¢„æµ‹ç½®ä¿¡åº¦**: {max(probability_positive, probability_negative):.2f}%
                """)
                
        except Exception as e:
            st.error(f"ç”Ÿæˆæ¨¡å‹è§£é‡Šå›¾æ—¶å‡ºé”™: {str(e)}")
            st.info("""
            **è§£å†³æ–¹æ¡ˆï¼š**
            1. æ¨¡å‹æ–‡ä»¶å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·é‡æ–°è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
            2. åˆ·æ–°é¡µé¢å¹¶é‡è¯•
            3. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»å¼€å‘äººå‘˜
            """)

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.header("å…³äºæœ¬åº”ç”¨")
    st.markdown(f"""
    ### å¼€å‘ä¿¡æ¯
    - **å¼€å‘å•ä½**: {AUTHOR_INFO["institution"]}
    - **ä½œè€…**: {AUTHOR_INFO["author"]}
    
    ### æ¨¡å‹ä¿¡æ¯
    - **ç®—æ³•**: XGBoost (æç«¯æ¢¯åº¦æå‡)
    - **è®­ç»ƒæ•°æ®**: ä¸´åºŠæ•°æ®
    - **é¢„æµ‹ç›®æ ‡**: å‹åŠ›æ€§æŸä¼¤(PI)é£é™©
    - **ç‰¹å¾æ•°é‡**: 8ä¸ªæŒ‡æ ‡
    
    ### ç‰¹å¾æè¿°
    - **FCTIæ€»åˆ†**: å®¶åº­ç…§é¡¾è€…èƒ½åŠ›é‡è¡¨æ€»åˆ† 0 ~ 40ï¼ˆæ— é‡çº²ï¼‰
    - **Age**: å¹´é¾„ 70 ~ 98ï¼ˆå²ï¼‰
    - **Ser**: è¡€æ¸…ç™½è›‹ç™½ 20.0 ~ 60.0 (g/L)
    - **Fra**: éª¨æŠ˜ç±»å‹ 14ç±» åŒ…æ‹¬é¢ˆæ¤éª¨æŠ˜ã€èƒ¸æ¤éª¨æŠ˜ã€è…°æ¤éª¨æŠ˜ã€è‚¡éª¨é¢ˆéª¨æŠ˜ã€è‚¡éª¨ç²—éš†é—´éª¨æŠ˜ã€è‚¡éª¨å¹²éª¨æŠ˜ã€èƒ«è…“éª¨ä¸Šæ®µéª¨æŠ˜ã€å°¾éª¨ç²‰ç¢æ€§éª¨æŠ˜ã€éª¶é«‚å…³èŠ‚è„±ä½ã€é«‹éª¨éª¨æŠ˜ã€é«Œéª¨ç²‰ç¢æ€§éª¨æŠ˜ã€é«‹å…³èŠ‚å†…éª¨æŠ˜ã€è„†æ€§éª¨æŠ˜ç­‰
    - **Air**: æ˜¯å¦ä½¿ç”¨æ°”å«åºŠæˆ–å……æ°”åºŠå«
    - **Com**: æ‚£åˆå¹¶ç—‡æ•°é‡ 0 ~ 8ï¼ˆä¸ªï¼‰  åŒ…æ‹¬ç¥ç»ç³»ç»Ÿç–¾ç—…ã€è‡ªèº«å…ç–«æ€§ç–¾ç—…ã€ç³–å°¿ç—…ã€æ°´è‚¿ã€ä¸­é£ã€ä¸‹è‚¢é™è„‰è¡€æ “ã€å† å¿ƒç—…å’Œé«˜è¡€å‹
    - **PCATæ€»åˆ†**: åŸºå±‚åŒ»ç–—è´¨é‡è¯„ä¼°é‡è¡¨æ€»åˆ† 1 ~ 4ï¼ˆæ— é‡çº²ï¼‰
    - **Mlu**: æ˜¯å¦ä¸ºå¤šå‘æ€§éª¨æŠ˜
    """)

# é¡µè„š
st.markdown("---")
st.markdown(
    f"""
    <div style='text-align: center; color: gray;'>
        ä¸´åºŠå†³ç­–æ”¯æŒå·¥å…· â€¢ {AUTHOR_INFO["institution"]} â€¢ {AUTHOR_INFO["author"]} â€¢ ä»…ä¾›å‚è€ƒ
    </div>
    """, 
    unsafe_allow_html=True
)

# æ·»åŠ SHAPå›¾ä¾‹è¯´æ˜
with st.expander("å¦‚ä½•è§£è¯»SHAPå›¾"):
    st.markdown("""
    ### SHAPåŠ›å›¾è§£è¯»
    - **çº¢è‰²ç®­å¤´**ï¼šå¢åŠ PIé£é™©çš„å› ç´ 
    - **è“è‰²ç®­å¤´**ï¼šé™ä½PIé£é™©çš„å› ç´   
    - **ç®­å¤´é•¿åº¦**ï¼šè¡¨ç¤ºè¯¥å› ç´ å½±å“ç¨‹åº¦çš„å¤§å°
    - **åŸºå‡†å€¼**ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„å¹³å‡é¢„æµ‹å€¼
    - **è¾“å‡ºå€¼**ï¼šå½“å‰æ‚£è€…çš„é¢„æµ‹æ¦‚ç‡
    
    ### SHAPç€‘å¸ƒå›¾è§£è¯»
    - **ä»ä¸Šåˆ°ä¸‹**ï¼šæ˜¾ç¤ºäº†æ¯ä¸ªç‰¹å¾å¦‚ä½•å°†é¢„æµ‹å€¼ä»åŸºå‡†å€¼æ¨åˆ°æœ€ç»ˆé¢„æµ‹å€¼
    - **æ¡å½¢é•¿åº¦**ï¼šè¡¨ç¤ºæ¯ä¸ªç‰¹å¾çš„å½±å“å¤§å°
    - **çº¢è‰²æ¡å½¢**ï¼šæ­£å‘å½±å“ï¼ˆå¢åŠ é£é™©ï¼‰
    - **è“è‰²æ¡å½¢**ï¼šè´Ÿå‘å½±å“ï¼ˆé™ä½é£é™©ï¼‰
    - **åº•éƒ¨å€¼**ï¼šæœ€ç»ˆé¢„æµ‹æ¦‚ç‡
    """)
